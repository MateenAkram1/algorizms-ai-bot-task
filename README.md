
# ğŸ›£ï¸ Uqaab Voice Assistant Prototype

A lightweight AI chatbot and voice recognition assistant for truck drivers and dispatchers to interact with the **Uqaab system** using natural language commands.

> ğŸ™ï¸ Speak naturally â€” get quick system replies like:  
> â€œUpdate my route to Lahoreâ€ or â€œWhatâ€™s my next delivery?â€

---

## ğŸ“Œ Features

âœ… Real-time **voice-to-text** (Vosk ASR)  
âœ… Intent detection via **rule-based NLP**  
âœ… Simulated **system responses**  
âœ… Optional **text-to-speech (TTS)** feedback  
âœ… Simple **Gradio web interface**

---

## ğŸ› ï¸ Tech Stack

| Component       | Library/Tool         |
|----------------|----------------------|
| Programming    | Python 3.x           |
| Speech-to-Text | [Vosk](https://alphacephei.com/vosk/) (offline ASR) |
| NLP            | Rule-based matching  |
| UI             | [Gradio](https://www.gradio.app/) |
| TTS (optional) | `pyttsx3`            |

---

## ğŸ’¬ Supported Voice Commands

- `Update my route to [City]`
- `Whatâ€™s my next job?`
- `When is my next delivery?`
- `Cancel my current job`
- `Confirm drop-off in [City]`

---

## ğŸš€ Setup Instructions

### 1. Clone This Repo

```bash
git <Link>
cd directory
```

### 2. Install Requirements

```bash
pip install -r requirements.txt
```

Contents of `requirements.txt`:

```
vosk
sounddevice
numpy
pyttsx3
gradio
```

### 3. Download & Setup Vosk Model

Download an English model (e.g., [vosk-model-small-en-us-0.15](https://alphacephei.com/vosk/models)) and extract it.

Place the extracted folder in the project directory and rename it to:

```
./model/
```

Example structure:

```
uqaab-voice-bot/
â”œâ”€â”€ model/
â”‚   â”œâ”€â”€ am
â”‚   â”œâ”€â”€ conf
â”‚   â””â”€â”€ ...
```

---

## â–¶ï¸ Running the App

```bash
python main.py
```

Open the Gradio UI in your browser. Link will be provided in the terminal when you run the main.py.  
Click â€œğŸ™ï¸ Press to Speakâ€, then say one of the supported phrases.

---

## ğŸ“‚ Project Structure

```
.
â”œâ”€â”€ main.py                # Gradio UI and logic
â”œâ”€â”€ voice_input.py         # Vosk voice recorder with silence detection
â”œâ”€â”€ intent_parser.py       # Rule-based NLP for command extraction
â”œâ”€â”€ response_generator.py  # Simulated system response
â”œâ”€â”€ text_to_speech.py      # Optional TTS using pyttsx3
â”œâ”€â”€ model/                 # Vosk offline model folder
â””â”€â”€ README.md
```

---

## ğŸ“ˆ Future Enhancements

- ğŸ“¡ Integrate real Uqaab API endpoints  
- ğŸŒ Multilingual support with other Vosk models  
- ğŸ—£ï¸ Use webrtcvad for advanced VAD  
- ğŸ§  Switch to Rasa or Dialogflow for advanced NLP  
- ğŸ–¥ï¸ Desktop version with PyQt or Electron

---

## ğŸ§‘â€ğŸ’» Developed By

**Mateen Akram**  

## ğŸ“„ License

This project is for internal prototyping and demonstration only. Not for production use.
